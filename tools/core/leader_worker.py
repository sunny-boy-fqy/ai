"""
AI CLI Leader-Worker æ ¸å¿ƒ
å®ç° Leader AI å’Œ Worker AI çš„åä½œæœºåˆ¶

åŠŸèƒ½ç‰¹æ€§:
- API è°ƒç”¨è‡ªåŠ¨é‡è¯•
- ä»»åŠ¡æ¢å¤ï¼ˆä¸­æ–­åå¯ç»§ç»­ï¼‰
- æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†
- å¹¶å‘ Worker æ‰§è¡Œ
- è¿›åº¦å¯è§†åŒ–
"""

import os
import sys
import json
import re
import asyncio
import time
import random
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Set
from contextlib import contextmanager
from ..config_mgr import ConfigManager
from ..plugin import PluginManager, MCPToolManager
from ..ui import UI
from .task_manager import TaskManager
from .input_handler import InputHandler

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from ..logger import debug, info, warn, error, api, task, set_log_level, DEBUG, INFO


@contextmanager
def suppress_stdout():
    """
    é™é»˜ stdout è¾“å‡ºçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    
    ä½¿ç”¨æ–‡ä»¶æè¿°ç¬¦çº§åˆ«çš„é‡å®šå‘ï¼Œå¯ä»¥æ•è·å­è¿›ç¨‹çš„è¾“å‡º
    """
    # ä¿å­˜åŸå§‹ stdout æ–‡ä»¶æè¿°ç¬¦
    original_stdout_fd = os.dup(1)
    original_stdout = sys.stdout
    
    try:
        # åˆ·æ–°ç¼“å†²åŒº
        sys.stdout.flush()
        
        # æ‰“å¼€ /dev/null
        devnull_fd = os.open(os.devnull, os.O_WRONLY)
        
        # é‡å®šå‘ stdout åˆ° /dev/null
        os.dup2(devnull_fd, 1)
        os.close(devnull_fd)
        
        # æ›´æ–° Python çš„ sys.stdout
        sys.stdout = open(os.devnull, 'w')
        
        yield
    finally:
        # åˆ·æ–°å¹¶æ¢å¤
        sys.stdout.flush()
        os.dup2(original_stdout_fd, 1)
        os.close(original_stdout_fd)
        sys.stdout = original_stdout


class MCPServerSuppressor:
    """MCP æœåŠ¡å™¨è¾“å‡ºæŠ‘åˆ¶å™¨"""
    
    _instance = None
    _shown = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    @classmethod
    def show_startup_message(cls, servers: List[str]):
        """æ˜¾ç¤º MCP æœåŠ¡å™¨å¯åŠ¨æç¤ºï¼ˆåªæ˜¾ç¤ºä¸€æ¬¡ï¼‰"""
        if not cls._shown and servers:
            UI.info(f"MCP ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œå·²åŠ è½½ {len(servers)} ä¸ªæ’ä»¶")
            cls._shown = True


class ModelInterface:
    """æ¨¡å‹æ¥å£ - ç”¨äºè°ƒç”¨å¤§æ¨¡å‹ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
    
    # é‡è¯•é…ç½®
    MAX_RETRIES = 3
    BASE_DELAY = 1.0
    MAX_DELAY = 30.0
    
    def __init__(self, config: Dict):
        self.config = config
        self.client = None
        self._init_client()
    
    def _init_client(self):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        try:
            from openai import OpenAI
            self.client = OpenAI(
                api_key=self.config.get("api_key"),
                base_url=self.config.get("base_url")
            )
            debug(f"æ¨¡å‹å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {self.config.get('model')}")
        except ImportError:
            error("æœªå®‰è£… openai åº“")
        except Exception as e:
            error(f"åˆå§‹åŒ–å®¢æˆ·ç«¯å¤±è´¥: {e}")
    
    def _should_retry(self, error: Exception) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•"""
        error_str = str(error).lower()
        retry_keywords = [
            'rate limit', '429', 'too many requests',
            'timeout', 'timed out', 'connection',
            'network', 'temporary', 'unavailable',
            'overloaded', 'capacity'
        ]
        return any(kw in error_str for kw in retry_keywords)
    
    def _calculate_delay(self, attempt: int) -> float:
        """è®¡ç®—é‡è¯•å»¶è¿Ÿï¼ˆæŒ‡æ•°é€€é¿ + æŠ–åŠ¨ï¼‰"""
        delay = min(self.BASE_DELAY * (2 ** attempt), self.MAX_DELAY)
        jitter = random.uniform(0.5, 1.5)
        return delay * jitter
    
    def call(
        self,
        prompt: str,
        system_prompt: str = None,
        tools: List[Dict] = None,
        stream: bool = False
    ) -> Tuple[str, List[Dict]]:
        """è°ƒç”¨æ¨¡å‹ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        if not self.client:
            return "å®¢æˆ·ç«¯æœªåˆå§‹åŒ–", []
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        last_error = None
        
        for attempt in range(self.MAX_RETRIES + 1):
            try:
                kwargs = {
                    "model": self.config.get("model"),
                    "messages": messages,
                }
                if tools:
                    kwargs["tools"] = tools
                
                api(f"è°ƒç”¨æ¨¡å‹: {self.config.get('model')} (å°è¯• {attempt + 1})")
                
                response = self.client.chat.completions.create(**kwargs)
                
                content = response.choices[0].message.content or ""
                tool_calls = []
                
                if response.choices[0].message.tool_calls:
                    for tc in response.choices[0].message.tool_calls:
                        tool_calls.append({
                            "id": tc.id,
                            "type": tc.type,
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        })
                
                if attempt > 0:
                    info(f"é‡è¯•æˆåŠŸ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                
                return content, tool_calls
                
            except Exception as e:
                last_error = e
                
                if self._should_retry(e) and attempt < self.MAX_RETRIES:
                    delay = self._calculate_delay(attempt)
                    warn(f"API è°ƒç”¨å¤±è´¥ï¼Œ{delay:.1f}ç§’åé‡è¯• ({attempt + 1}/{self.MAX_RETRIES}): {e}")
                    time.sleep(delay)
                else:
                    break
        
        error_msg = f"è°ƒç”¨å¤±è´¥ (é‡è¯• {self.MAX_RETRIES} æ¬¡å): {last_error}"
        error(error_msg)
        return error_msg, []
    
    def _clean_model_output(self, content: str) -> str:
        """æ¸…ç†æ¨¡å‹è¾“å‡º"""
        if not content:
            return content
        
        patterns = [
            r'<\|tool_calls_section_begin\|>',
            r'<\|tool_calls_section_end\|>',
            r'<\|tool_call_begin\|>',
            r'<\|tool_call_end\|>',
            r'<\|tool_call_argument_begin\|>',
            r'<\|tool_call_argument_end\|>',
            r'<\|tool_call_argument\|>',
            r'<\|.*?\|>',
        ]
        
        cleaned = content
        for pattern in patterns:
            cleaned = re.sub(pattern, '', cleaned)
        
        cleaned = re.sub(r'functions\.\w+:\d+\s*', '', cleaned)
        cleaned = re.sub(r'\{\s*"[^"]+"\s*:\s*"[^"]*"[^}]*\}\s*', '', cleaned)
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        
        return cleaned
    
    def _parse_tool_calls_from_text(self, content: str) -> List[Dict]:
        """ä»æ–‡æœ¬ä¸­è§£æå·¥å…·è°ƒç”¨"""
        tool_calls = []
        
        # æ¨¡å¼1: functions.name:args
        pattern1 = r'functions\.([\w_]+):(\d+)\s*\n?\s*(\{.*?\})'
        matches1 = re.findall(pattern1, content, re.DOTALL)
        
        for match in matches1:
            func_name, idx, args_str = match
            try:
                args = json.loads(args_str)
                tool_calls.append({
                    "id": f"tc_{idx}",
                    "type": "function",
                    "function": {
                        "name": func_name,
                        "arguments": json.dumps(args)
                    }
                })
            except json.JSONDecodeError:
                continue
        
        # æ¨¡å¼2: JSON ä»£ç å—
        pattern2 = r'```json\s*(.*?)\s*```'
        matches2 = re.findall(pattern2, content, re.DOTALL)
        
        for match in matches2:
            try:
                data = json.loads(match)
                if isinstance(data, dict) and "name" in data and "arguments" in data:
                    tool_calls.append({
                        "id": f"tc_{len(tool_calls)}",
                        "type": "function",
                        "function": {
                            "name": data["name"],
                            "arguments": json.dumps(data["arguments"])
                        }
                    })
            except json.JSONDecodeError:
                continue
        
        return tool_calls
    
    async def call_async(
        self,
        prompt: str,
        system_prompt: str = None,
        tools: List[Dict] = None,
        stream: bool = True
    ) -> Tuple[str, List[Dict]]:
        """å¼‚æ­¥è°ƒç”¨æ¨¡å‹ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        if not self.client:
            return "å®¢æˆ·ç«¯æœªåˆå§‹åŒ–", []
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        last_error = None
        
        for attempt in range(self.MAX_RETRIES + 1):
            try:
                kwargs = {
                    "model": self.config.get("model"),
                    "messages": messages,
                    "stream": stream
                }
                if tools:
                    kwargs["tools"] = tools
                
                api(f"å¼‚æ­¥è°ƒç”¨æ¨¡å‹: {self.config.get('model')} (å°è¯• {attempt + 1})")
                
                response = self.client.chat.completions.create(**kwargs)
                
                if stream:
                    full_content = ""
                    tool_calls = []
                    
                    for chunk in response:
                        if not chunk.choices:
                            continue
                        
                        delta = chunk.choices[0].delta
                        
                        if delta.content:
                            raw_content = delta.content
                            clean_content = self._clean_model_output(raw_content)
                            if clean_content:
                                print(clean_content, end="", flush=True)
                            full_content += raw_content
                        
                        if delta.tool_calls:
                            for tc in delta.tool_calls:
                                while len(tool_calls) <= tc.index:
                                    tool_calls.append({
                                        "id": f"tc_{tc.index}",
                                        "type": "function",
                                        "function": {"name": "", "arguments": ""}
                                    })
                                target = tool_calls[tc.index]
                                if tc.id:
                                    target["id"] = tc.id
                                if tc.function.name:
                                    target["function"]["name"] += tc.function.name
                                if tc.function.arguments:
                                    target["function"]["arguments"] += tc.function.arguments
                    
                    print()
                    
                    full_content = self._clean_model_output(full_content)
                    
                    if not tool_calls and tools:
                        tool_calls = self._parse_tool_calls_from_text(full_content)
                    
                    if attempt > 0:
                        info(f"é‡è¯•æˆåŠŸ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                    
                    return full_content, tool_calls
                else:
                    content = response.choices[0].message.content or ""
                    content = self._clean_model_output(content)
                    tool_calls = []
                    
                    if response.choices[0].message.tool_calls:
                        for tc in response.choices[0].message.tool_calls:
                            tool_calls.append({
                                "id": tc.id,
                                "type": tc.type,
                                "function": {
                                    "name": tc.function.name,
                                    "arguments": tc.function.arguments
                                }
                            })
                    
                    if not tool_calls and tools:
                        tool_calls = self._parse_tool_calls_from_text(content)
                    
                    return content, tool_calls
                    
            except Exception as e:
                last_error = e
                
                if self._should_retry(e) and attempt < self.MAX_RETRIES:
                    delay = self._calculate_delay(attempt)
                    warn(f"API è°ƒç”¨å¤±è´¥ï¼Œ{delay:.1f}ç§’åé‡è¯• ({attempt + 1}/{self.MAX_RETRIES}): {e}")
                    await asyncio.sleep(delay)
                else:
                    break
        
        error_msg = f"è°ƒç”¨å¤±è´¥ (é‡è¯• {self.MAX_RETRIES} æ¬¡å): {last_error}"
        error(error_msg)
        return error_msg, []
    
    async def call_with_messages(
        self,
        messages: List[Dict],
        tools: List[Dict] = None,
        stream: bool = True
    ) -> Tuple[str, List[Dict]]:
        """
        ä½¿ç”¨å®Œæ•´æ¶ˆæ¯å†å²è°ƒç”¨æ¨¡å‹ï¼ˆç”¨äºå·¥å…·è°ƒç”¨å¾ªç¯ï¼‰
        
        Args:
            messages: å®Œæ•´çš„æ¶ˆæ¯å†å²
            tools: å·¥å…·å®šä¹‰
            stream: æ˜¯å¦æµå¼è¾“å‡º
            
        Returns:
            (å“åº”æ–‡æœ¬, å·¥å…·è°ƒç”¨åˆ—è¡¨)
        """
        if not self.client:
            return "å®¢æˆ·ç«¯æœªåˆå§‹åŒ–", []
        
        try:
            kwargs = {
                "model": self.config.get("model"),
                "messages": messages,
                "stream": stream
            }
            if tools:
                kwargs["tools"] = tools
            
            response = self.client.chat.completions.create(**kwargs)
            
            if stream:
                full_content = ""
                tool_calls = []
                
                for chunk in response:
                    if not chunk.choices:
                        continue
                    
                    delta = chunk.choices[0].delta
                    
                    if delta.content:
                        raw_content = delta.content
                        clean_content = self._clean_model_output(raw_content)
                        if clean_content:
                            print(clean_content, end="", flush=True)
                        full_content += raw_content
                    
                    if delta.tool_calls:
                        for tc in delta.tool_calls:
                            while len(tool_calls) <= tc.index:
                                tool_calls.append({
                                    "id": f"tc_{tc.index}",
                                    "type": "function",
                                    "function": {"name": "", "arguments": ""}
                                })
                            target = tool_calls[tc.index]
                            if tc.id:
                                target["id"] = tc.id
                            if tc.function.name:
                                target["function"]["name"] += tc.function.name
                            if tc.function.arguments:
                                target["function"]["arguments"] += tc.function.arguments
                
                if full_content:
                    print()
                
                full_content = self._clean_model_output(full_content)
                
                return full_content, tool_calls
            else:
                content = response.choices[0].message.content or ""
                content = self._clean_model_output(content)
                tool_calls = []
                
                if response.choices[0].message.tool_calls:
                    for tc in response.choices[0].message.tool_calls:
                        tool_calls.append({
                            "id": tc.id,
                            "type": tc.type,
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        })
                
                return content, tool_calls
                
        except Exception as e:
            return f"è°ƒç”¨å¤±è´¥: {e}", []
    
    async def call_with_messages(
        self,
        messages: List[Dict],
        tools: List[Dict] = None,
        stream: bool = True
    ) -> Tuple[str, List[Dict]]:
        """
        ä½¿ç”¨å®Œæ•´æ¶ˆæ¯å†å²è°ƒç”¨æ¨¡å‹ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼Œç”¨äºå·¥å…·è°ƒç”¨å¾ªç¯ï¼‰
        
        Args:
            messages: å®Œæ•´çš„æ¶ˆæ¯å†å²
            tools: å·¥å…·å®šä¹‰
            stream: æ˜¯å¦æµå¼è¾“å‡º
            
        Returns:
            (å“åº”æ–‡æœ¬, å·¥å…·è°ƒç”¨åˆ—è¡¨)
        """
        if not self.client:
            return "å®¢æˆ·ç«¯æœªåˆå§‹åŒ–", []
        
        last_error = None
        
        for attempt in range(self.MAX_RETRIES + 1):
            try:
                kwargs = {
                    "model": self.config.get("model"),
                    "messages": messages,
                    "stream": stream
                }
                if tools:
                    kwargs["tools"] = tools
                
                api(f"è°ƒç”¨æ¨¡å‹ (æ¶ˆæ¯å†å²: {len(messages)}æ¡) (å°è¯• {attempt + 1})")
                
                response = self.client.chat.completions.create(**kwargs)
                
                if stream:
                    full_content = ""
                    tool_calls = []
                    
                    for chunk in response:
                        if not chunk.choices:
                            continue
                        
                        delta = chunk.choices[0].delta
                        
                        if delta.content:
                            raw_content = delta.content
                            clean_content = self._clean_model_output(raw_content)
                            if clean_content:
                                print(clean_content, end="", flush=True)
                            full_content += raw_content
                        
                        if delta.tool_calls:
                            for tc in delta.tool_calls:
                                while len(tool_calls) <= tc.index:
                                    tool_calls.append({
                                        "id": f"tc_{tc.index}",
                                        "type": "function",
                                        "function": {"name": "", "arguments": ""}
                                    })
                                target = tool_calls[tc.index]
                                if tc.id:
                                    target["id"] = tc.id
                                if tc.function.name:
                                    target["function"]["name"] += tc.function.name
                                if tc.function.arguments:
                                    target["function"]["arguments"] += tc.function.arguments
                    
                    if full_content:
                        print()
                    
                    full_content = self._clean_model_output(full_content)
                    
                    if attempt > 0:
                        info(f"é‡è¯•æˆåŠŸ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                    
                    return full_content, tool_calls
                else:
                    content = response.choices[0].message.content or ""
                    content = self._clean_model_output(content)
                    tool_calls = []
                    
                    if response.choices[0].message.tool_calls:
                        for tc in response.choices[0].message.tool_calls:
                            tool_calls.append({
                                "id": tc.id,
                                "type": tc.type,
                                "function": {
                                    "name": tc.function.name,
                                    "arguments": tc.function.arguments
                                }
                            })
                    
                    return content, tool_calls
                    
            except Exception as e:
                last_error = e
                
                if self._should_retry(e) and attempt < self.MAX_RETRIES:
                    delay = self._calculate_delay(attempt)
                    warn(f"API è°ƒç”¨å¤±è´¥ï¼Œ{delay:.1f}ç§’åé‡è¯• ({attempt + 1}/{self.MAX_RETRIES}): {e}")
                    await asyncio.sleep(delay)
                else:
                    break
        
        error_msg = f"è°ƒç”¨å¤±è´¥ (é‡è¯• {self.MAX_RETRIES} æ¬¡å): {last_error}"
        error(error_msg)
        return error_msg, []


class LeaderAI:
    """Leader AI - ä»»åŠ¡è§„åˆ’å’Œåè°ƒ"""
    
    def __init__(self, ai_dir: str):
        self.ai_dir = ai_dir
        self.root_dir = os.path.dirname(ai_dir)
        
        # åŠ è½½é…ç½®
        self.config = self._load_config("leader")
        self.worker_config = self._load_config("worker")
        
        # åˆå§‹åŒ–æ¨¡å—
        self.model = ModelInterface(self.config) if self.config else None
        self.worker_model = ModelInterface(self.worker_config) if self.worker_config else None
        self.task_manager = TaskManager(ai_dir)
        self.mcp_manager = MCPToolManager()
        
        # MCP å·¥å…·æƒé™ç®¡ç†
        self._mcp_permissions = {
            "allowed_plugins": set(),      # æ°¸ä¹…å…è®¸çš„æ’ä»¶
            "session_allowed": set(),      # æœ¬æ¬¡ä»»åŠ¡å…è®¸çš„æ’ä»¶
            "denied_tools": set(),         # æœ¬æ¬¡æ‹’ç»çš„å·¥å…·
        }
        
        # è¯»å–æŒ‡å—
        self.leader_guide = self._load_guide("README_for_leader.md")
        self.worker_guide = self._load_guide("README_for_worker.md")
        
        # åŠ è½½å¯¹è¯å†å²ï¼ˆä¿®å¤ï¼šæ·»åŠ æŒä¹…åŒ–ä¸Šä¸‹æ–‡è®°å¿†ï¼‰
        self.history_file = os.path.join(ai_dir, "leader_history.json")
        self.messages = self._load_history()
        
        # ä»»åŠ¡æ¢å¤ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„ä»»åŠ¡
        self._check_pending_tasks()
    
    def _check_mcp_permission(self, tool_name: str) -> int:
        """
        æ£€æŸ¥ MCP å·¥å…·è°ƒç”¨æƒé™
        
        Returns:
            0: æ‹’ç»
            1: å…è®¸æœ¬æ¬¡
            2: å…è®¸è¯¥æ’ä»¶æ‰€æœ‰å‘½ä»¤
            3: æœ¬æ¬¡ä»»åŠ¡æ°¸ä¹…å…è®¸
        """
        # è§£ææ’ä»¶å
        if "__" not in tool_name:
            return 1  # é MCP å·¥å…·ï¼Œç›´æ¥å…è®¸
        
        plugin_name = tool_name.split("__")[0]
        
        # æ£€æŸ¥æ˜¯å¦å·²åœ¨æ‹’ç»åˆ—è¡¨
        if tool_name in self._mcp_permissions["denied_tools"]:
            return 0
        
        # æ£€æŸ¥æ˜¯å¦æ°¸ä¹…å…è®¸è¯¥æ’ä»¶
        if plugin_name in self._mcp_permissions["allowed_plugins"]:
            return 2
        
        # æ£€æŸ¥æ˜¯å¦æœ¬æ¬¡ä»»åŠ¡å…è®¸
        if plugin_name in self._mcp_permissions["session_allowed"]:
            return 3
        
        # éœ€è¦ç”¨æˆ·ç¡®è®¤
        return -1
    
    def _request_mcp_permission(self, tool_name: str, args: dict) -> int:
        """
        è¯·æ±‚ç”¨æˆ·ç¡®è®¤ MCP å·¥å…·è°ƒç”¨
        
        Returns:
            0: æ‹’ç»
            1: å…è®¸æœ¬æ¬¡
            2: å…è®¸è¯¥æ’ä»¶æ‰€æœ‰å‘½ä»¤
            3: æœ¬æ¬¡ä»»åŠ¡æ°¸ä¹…å…è®¸
        """
        plugin_name = tool_name.split("__")[0] if "__" in tool_name else "unknown"
        tool_action = tool_name.split("__")[1] if "__" in tool_name else tool_name
        
        # æ ¼å¼åŒ–å‚æ•°æ˜¾ç¤º
        args_str = ""
        if args:
            for key, value in list(args.items())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªå‚æ•°
                value_str = str(value)
                if len(value_str) > 100:
                    value_str = value_str[:100] + "..."
                args_str += f"    {key}: {value_str}\n"
            if len(args) > 5:
                args_str += f"    ... (å…± {len(args)} ä¸ªå‚æ•°)\n"
        
        print()
        UI.section("ğŸ”’ MCP å·¥å…·è°ƒç”¨ç¡®è®¤")
        print(f"  æ’ä»¶: {UI.CYAN}{plugin_name}{UI.END}")
        print(f"  å·¥å…·: {UI.GREEN}{tool_action}{UI.END}")
        if args_str:
            print(f"  å‚æ•°:")
            print(args_str.rstrip())
        print()
        print(f"  {UI.BOLD}è¯·é€‰æ‹©æ“ä½œ:{UI.END}")
        print(f"    {UI.RED}1. æ‹’ç»{UI.END} - ä¸æ‰§è¡Œæ­¤æ“ä½œ")
        print(f"    {UI.YELLOW}2. æœ¬æ¬¡å…è®¸{UI.END} - ä»…å…è®¸æœ¬æ¬¡è°ƒç”¨")
        print(f"    {UI.GREEN}3. å…è®¸è¯¥æ’ä»¶æ‰€æœ‰å‘½ä»¤{UI.END} - æœ¬æ¬¡ä»»åŠ¡ä¸­ä¿¡ä»»æ­¤æ’ä»¶")
        print(f"    {UI.CYAN}4. å…è®¸æ‰€æœ‰æ’ä»¶{UI.END} - æœ¬æ¬¡ä»»åŠ¡ä¸å†è¯¢é—®")
        print()
        
        while True:
            try:
                choice = input(f"  è¯·é€‰æ‹© [1-4]: ").strip()
                if choice == "1":
                    return 0
                elif choice == "2":
                    return 1
                elif choice == "3":
                    plugin_name = tool_name.split("__")[0] if "__" in tool_name else ""
                    if plugin_name:
                        self._mcp_permissions["allowed_plugins"].add(plugin_name)
                    return 2
                elif choice == "4":
                    self._mcp_permissions["session_allowed"].add("__all__")
                    return 3
                else:
                    UI.warn("è¯·è¾“å…¥ 1-4")
            except (EOFError, KeyboardInterrupt):
                print()
                return 0
    
    def _check_pending_tasks(self):
        """æ£€æŸ¥æœªå®Œæˆçš„ä»»åŠ¡ï¼ˆä»»åŠ¡æ¢å¤åŠŸèƒ½ï¼‰"""
        in_progress = self.task_manager.get_in_progress_tasks()
        pending = self.task_manager.get_pending_tasks()
        
        if in_progress or pending:
            debug(f"å‘ç° {len(in_progress)} ä¸ªè¿›è¡Œä¸­ä»»åŠ¡, {len(pending)} ä¸ªå¾…å¤„ç†ä»»åŠ¡")
    
    def _load_config(self, role: str) -> Optional[Dict]:
        """åŠ è½½æ¨¡å‹é…ç½®"""
        config_file = os.path.join(self.ai_dir, f"{role}_model.config")
        if not os.path.exists(config_file):
            return None
        
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return None
    
    def _load_guide(self, filename: str) -> str:
        """åŠ è½½æŒ‡å—æ–‡æ¡£"""
        template_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "templates", filename)
        if os.path.exists(template_path):
            try:
                with open(template_path, 'r', encoding='utf-8') as f:
                    return f.read()
            except:
                pass
        return ""
    def is_ready(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å‡†å¤‡å°±ç»ª"""
        return self.model is not None and self.worker_model is not None
    
    def _load_history(self) -> List[Dict]:
        """åŠ è½½å¯¹è¯å†å²ï¼ˆä¿®å¤P0ï¼šæ·»åŠ å†å²åŠ è½½ï¼‰"""
        if os.path.exists(self.history_file):
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        
        # åˆå§‹åŒ–ä¸ºåŒ…å«ç³»ç»Ÿæç¤ºçš„åˆ—è¡¨
        return [{"role": "system", "content": self._build_system_prompt()}]
    
    def _save_history(self):
        """ä¿å­˜å¯¹è¯å†å²ï¼ˆä¿®å¤P0ï¼šæ·»åŠ å†å²ä¿å­˜ï¼‰"""
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(self.messages, f, ensure_ascii=False, indent=2)
        except Exception as e:
            UI.warn(f"ä¿å­˜å¯¹è¯å†å²å¤±è´¥: {e}")
    
    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤º"""
        # è·å–ä»»åŠ¡åˆ—è¡¨
        tasks = self.task_manager.get_all_tasks()
        tasks_summary = ""
        if tasks:
            tasks_summary = "\nå½“å‰ä»»åŠ¡åˆ—è¡¨:\n"
            for t in tasks[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                status_icon = {"pending": "â—‹", "in_progress": "â—", "completed": "â—", "failed": "âœ—"}.get(t.get("status"), "â—‹")
                deps = t.get("dependencies", [])
                deps_str = f" [ä¾èµ–: {', '.join(deps)}]" if deps else ""
                tasks_summary += f"  {status_icon} {t.get('id')}: {t.get('title')}{deps_str}\n"
        
        return f"""ä½ æ˜¯ Leader AIï¼Œè´Ÿè´£ä»»åŠ¡è§„åˆ’å’Œåè°ƒã€‚

{self.leader_guide}

å½“å‰é¡¹ç›®ç›®å½•: {self.root_dir}

## ğŸš¨ æ ¸å¿ƒå·¥ä½œæµç¨‹ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰

1. **æ¥æ”¶éœ€æ±‚** â†’ åˆ†æç”¨æˆ·éœ€æ±‚
2. **åˆ›å»ºä»»åŠ¡** â†’ ä½¿ç”¨ `create_task` å·¥å…·åˆ›å»ºä»»åŠ¡
3. **åˆ†é…ä»»åŠ¡** â†’ ä½¿ç”¨ `assign_task` å·¥å…·åˆ†é…ç»™ Worker AI
4. **ç­‰å¾…å®Œæˆ** â†’ Worker æ‰§è¡Œå®Œæ¯•åæ£€æŸ¥ç»“æœ
5. **ç»§ç»­æˆ–æ±‡æŠ¥** â†’ åˆ†é…ä¸‹ä¸€ä¸ªä»»åŠ¡æˆ–å‘ç”¨æˆ·æ±‡æŠ¥

## âš ï¸ é‡è¦è§„åˆ™

- **ç¦æ­¢ç›´æ¥ä½¿ç”¨ MCP å·¥å…·æ‰§è¡Œä»£ç ç¼–å†™ä»»åŠ¡**ï¼ˆå¦‚ write_fileï¼‰
- æ‰€æœ‰æ‰§è¡Œç±»ä»»åŠ¡å¿…é¡»é€šè¿‡ `assign_task` åˆ†é…ç»™ Worker AI
- ä½ åªè´Ÿè´£ï¼šè§„åˆ’ã€åˆ›å»ºä»»åŠ¡ã€åˆ†é…ä»»åŠ¡ã€ç›‘æ§è¿›åº¦ã€æ±‡æŠ¥ç»“æœ

## ğŸ”— ä»»åŠ¡ä¾èµ–æœºåˆ¶

åˆ›å»ºä»»åŠ¡æ—¶å¯ä»¥æŒ‡å®š `dependencies` å‚æ•°ï¼Œè¡¨ç¤ºè¯¥ä»»åŠ¡ä¾èµ–çš„å…¶ä»–ä»»åŠ¡ï¼š
- åªæœ‰å½“æ‰€æœ‰ä¾èµ–ä»»åŠ¡å®Œæˆåï¼Œå½“å‰ä»»åŠ¡æ‰ä¼šè¢«æ‰§è¡Œ
- ä½¿ç”¨ `assign_tasks_parallel` æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹ä¾èµ–å¹¶æŒ‰é¡ºåºæ‰§è¡Œ
- ç³»ç»Ÿè¿˜ä¼šè‡ªåŠ¨æ£€æµ‹æ–‡ä»¶å†²çªï¼Œé¿å…å¤šä¸ª Worker åŒæ—¶ä¿®æ”¹åŒä¸€æ–‡ä»¶

**ç¤ºä¾‹**ï¼š
```json
{{
  "title": "æµ‹è¯•ç”¨æˆ·æ¨¡å—",
  "description": "ç¼–å†™ç”¨æˆ·æ¨¡å—çš„å•å…ƒæµ‹è¯•",
  "dependencies": ["task_001"],  // ç­‰å¾… task_001 å®Œæˆ
  "files_to_modify": ["tests/test_user.py"]
}}
```

å½“å‰ä»»åŠ¡çŠ¶æ€:
{json.dumps(self.task_manager.get_statistics(), ensure_ascii=False, indent=2)}
{tasks_summary}
"""
    
    def _summarize_old_messages(self, messages: List[Dict], keep_recent: int = 10) -> List[Dict]:
        """
        æ™ºèƒ½æ‘˜è¦æ—§æ¶ˆæ¯ï¼ˆä¸Šä¸‹æ–‡çª—å£ç®¡ç†ï¼‰
        
        ä¿ç•™ç­–ç•¥ï¼š
        - ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
        - ä¿ç•™æœ€è¿‘ N æ¡æ¶ˆæ¯
        - å°†ä¸­é—´æ¶ˆæ¯æ›¿æ¢ä¸ºæ‘˜è¦
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            keep_recent: ä¿ç•™æœ€è¿‘å¤šå°‘æ¡æ¶ˆæ¯
            
        Returns:
            å‹ç¼©åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        if len(messages) <= keep_recent + 2:
            return messages
        
        # åˆ†ç¦»ç³»ç»Ÿæ¶ˆæ¯
        system_msg = None
        other_messages = []
        for m in messages:
            if m.get("role") == "system":
                system_msg = m
            else:
                other_messages.append(m)
        
        # ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
        recent_messages = other_messages[-keep_recent:]
        old_messages = other_messages[:-keep_recent]
        
        if not old_messages:
            return messages
        
        # ç”Ÿæˆæ‘˜è¦
        summary_parts = []
        for m in old_messages:
            role = m.get("role", "unknown")
            content = m.get("content", "")
            
            if role == "user":
                summary_parts.append(f"ç”¨æˆ·: {content[:100]}...")
            elif role == "assistant":
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if m.get("tool_calls"):
                    tool_names = [tc.get("function", {}).get("name", "") for tc in m["tool_calls"]]
                    summary_parts.append(f"åŠ©æ‰‹è°ƒç”¨äº†å·¥å…·: {', '.join(tool_names[:3])}")
                elif content:
                    summary_parts.append(f"åŠ©æ‰‹: {content[:100]}...")
            elif role == "tool":
                summary_parts.append(f"å·¥å…·ç»“æœ: {str(content)[:50]}...")
        
        # åˆ›å»ºæ‘˜è¦æ¶ˆæ¯
        summary_text = "ã€å†å²æ‘˜è¦ã€‘\n" + "\n".join(summary_parts[-20:])  # æœ€å¤š20æ¡æ‘˜è¦
        
        summary_msg = {
            "role": "user",
            "content": f"[ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆçš„å†å²æ‘˜è¦]\n{summary_text}\n\nè¯·ç»§ç»­åŸºäºä»¥ä¸Šå†å²ä¸Šä¸‹æ–‡å·¥ä½œã€‚"
        }
        
        # ç»„åˆç»“æœ
        result = []
        if system_msg:
            result.append(system_msg)
        result.append(summary_msg)
        result.extend(recent_messages)
        
        debug(f"ä¸Šä¸‹æ–‡å‹ç¼©: {len(messages)} -> {len(result)} æ¡æ¶ˆæ¯")
        
        return result
    
    def _manage_context(self, max_messages: int = 50) -> bool:
        """
        ç®¡ç†ä¸Šä¸‹æ–‡çª—å£ï¼Œé˜²æ­¢æº¢å‡º
        
        Args:
            max_messages: æœ€å¤§æ¶ˆæ¯æ•°é‡
            
        Returns:
            æ˜¯å¦è¿›è¡Œäº†å‹ç¼©
        """
        if len(self.messages) <= max_messages:
            return False
        
        warn(f"ä¸Šä¸‹æ–‡æ¶ˆæ¯è¿‡å¤š ({len(self.messages)} æ¡)ï¼Œæ­£åœ¨è¿›è¡Œæ™ºèƒ½å‹ç¼©...")
        
        # è¿›è¡Œæ™ºèƒ½å‹ç¼©
        self.messages = self._summarize_old_messages(self.messages, keep_recent=15)
        
        # ä¿å­˜å‹ç¼©åçš„å†å²
        self._save_history()
        
        return True
    
    async def start_session(self):
        """å¯åŠ¨ Leader ä¼šè¯"""
        if not self.is_ready():
            UI.error("Leader AI æœªæ­£ç¡®é…ç½®")
            return
        
        # é™é»˜åˆå§‹åŒ– MCP å·¥å…·ï¼ˆéšè—æœåŠ¡å™¨å¯åŠ¨ä¿¡æ¯ï¼‰
        with suppress_stdout():
            await self.mcp_manager.initialize(silent=True)
        
        # æ˜¾ç¤º MCP å¯åŠ¨æç¤º
        MCPServerSuppressor.show_startup_message(list(self.mcp_manager.server_params.keys()))
        
        UI.section("Leader AI ä¼šè¯")
        print(f"  é¡¹ç›®ç›®å½•: {self.root_dir}")
        print(f"  Leader æ¨¡å‹: {self.config.get('model')}")
        print(f"  Worker æ¨¡å‹: {self.worker_config.get('model')}")
        print()
        print("  å¤šè¡Œè¾“å…¥æ”¯æŒ:")
        print("    - ä»¥ \\ ç»“å°¾ç»§ç»­è¾“å…¥ä¸‹ä¸€è¡Œ")
        print("    - è¾“å…¥ ``` å¼€å§‹å¤šè¡Œå—ï¼Œå†è¾“å…¥ ``` ç»“æŸ")
        print("    - æˆ–è¾“å…¥ \"\"\" å¼€å§‹å¤šè¡Œå—ï¼Œå†è¾“å…¥ \"\"\" ç»“æŸ")
        print()
        print("  å‘½ä»¤:")
        print("    - exit: é€€å‡º")
        print("    - status: æŸ¥çœ‹è¿›åº¦")
        print("    - clear: æ¸…ç©ºå·²å®Œæˆçš„ä»»åŠ¡")
        print()
        
        input_handler = InputHandler("", allow_multiline=True)
        
        while True:
            try:
                print(f"{UI.CYAN}Leader>{UI.END} ", end="", flush=True)
                user_input = input_handler.get_input()
                
                if not user_input:
                    continue
                
                if user_input.lower() in ["exit", "quit"]:
                    break
                
                if user_input.lower() == "status":
                    self.task_manager.show_progress()
                    continue
                
                if user_input.lower() == "clear":
                    self.task_manager.clear_completed_tasks()
                    # åŒæ—¶æ¸…ç©ºå¯¹è¯å†å²
                    system_prompt = self._build_system_prompt()
                    self.messages = [{"role": "system", "content": system_prompt}]
                    self._save_history()
                    UI.success("å·²æ¸…ç©ºä»»åŠ¡å’Œå¯¹è¯å†å²")
                    continue
                
                # å¤„ç†ç”¨æˆ·è¾“å…¥
                await self.process_user_input(user_input)
                
            except KeyboardInterrupt:
                print("\n")
                break
    
    async def process_user_input(self, user_input: str):
        """å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆä¿®å¤P0ï¼šä½¿ç”¨æŒä¹…åŒ–çš„ä¸Šä¸‹æ–‡è®°å¿†ï¼‰"""
        # è·å– MCP å·¥å…·å®šä¹‰
        tools = await self.mcp_manager.get_tools()
        
        # æ·»åŠ è¿›åŒ–å·¥å…·
        tools.extend(self._get_evolution_tools())
        
        # æ›´æ–°ç³»ç»Ÿæç¤ºï¼ˆä»»åŠ¡çŠ¶æ€å¯èƒ½å·²å˜åŒ–ï¼‰
        updated_system_prompt = self._build_system_prompt()
        
        # æ›´æ–°self.messagesçš„ç¬¬ä¸€æ¡ç³»ç»Ÿæ¶ˆæ¯
        if self.messages and self.messages[0]["role"] == "system":
            self.messages[0]["content"] = updated_system_prompt
        else:
            self.messages.insert(0, {"role": "system", "content": updated_system_prompt})
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        self.messages.append({"role": "user", "content": user_input})
        
        # è°ƒç”¨æ¨¡å‹ï¼ˆä½¿ç”¨call_with_messagesä»¥ä½¿ç”¨å®Œæ•´å†å²ï¼‰
        print(f"\n{UI.BLUE}[Leader]{UI.END} ", end="", flush=True)
        response, tool_calls = await self.model.call_with_messages(self.messages, tools, stream=True)
        
        # å¦‚æœæœ‰å“åº”å†…å®¹ï¼Œæ·»åŠ åˆ°å†å²
        if response:
            self.messages.append({"role": "assistant", "content": response})
        
        # å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯
        if tool_calls:
            await self._handle_tool_calls_loop(tool_calls, tools)
        
        # ä¿å­˜å†å²
        self._save_history()
        
        # æ˜¾ç¤ºä»»åŠ¡çŠ¶æ€
        self.task_manager.show_progress()
    
    async def _handle_tool_calls_loop(self, tool_calls: List[Dict], tools: List[Dict]):
        """
        å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯ï¼ˆä¿®å¤P0ï¼šç›´æ¥ä½¿ç”¨self.messagesï¼‰
        
        Args:
            tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨
            tools: å·¥å…·å®šä¹‰
        """
        max_iterations = 20
        iteration = 0
        
        while tool_calls and iteration < max_iterations:
            iteration += 1
            
            # æ·»åŠ åŠ©æ‰‹å“åº”ï¼ˆå·¥å…·è°ƒç”¨ï¼‰
            self.messages.append({
                "role": "assistant",
                "content": None,
                "tool_calls": tool_calls
            })
            
            # å¤„ç†æ‰€æœ‰å·¥å…·è°ƒç”¨
            for tc in tool_calls:
                name = tc["function"]["name"]
                try:
                    args = json.loads(tc["function"]["arguments"])
                except:
                    args = {}
                
                UI.info(f"è°ƒç”¨: {name}")
                
                # ===== ä»»åŠ¡ç®¡ç†å·¥å…· =====
                if name == "create_task":
                    task = self.task_manager.create_task(
                        title=args.get("title", "æœªå‘½åä»»åŠ¡"),
                        description=args.get("description", ""),
                        task_type=args.get("type", "code"),
                        priority=args.get("priority", 3),
                        dependencies=args.get("dependencies", []),
                        files_to_modify=args.get("files_to_modify", []),
                        acceptance_criteria=args.get("acceptance_criteria", [])
                    )
                    
                    # æ„å»ºç»“æœæ¶ˆæ¯
                    result = f"ä»»åŠ¡å·²åˆ›å»º: {task['id']}\næ ‡é¢˜: {task['title']}"
                    if task.get("dependencies"):
                        result += f"\nä¾èµ–: {', '.join(task['dependencies'])}"
                    result += "\nè¯·ä½¿ç”¨ assign_task å·¥å…·å°†æ­¤ä»»åŠ¡åˆ†é…ç»™ Worker AI æ‰§è¡Œã€‚"
                    UI.success(f"ä»»åŠ¡å·²åˆ›å»º: {task['id']}")
                
                elif name == "assign_task":
                    task_id = args.get("task_id")
                    instructions = args.get("instructions", "")
                    
                    task = self.task_manager.get_task(task_id)
                    if not task:
                        result = f"é”™è¯¯: æœªæ‰¾åˆ°ä»»åŠ¡ {task_id}"
                    elif task.get("status") != "pending":
                        result = f"é”™è¯¯: ä»»åŠ¡ {task_id} çŠ¶æ€ä¸º {task.get('status')}ï¼Œä¸æ˜¯å¾…å¤„ç†çŠ¶æ€"
                    else:
                        # æ£€æŸ¥ä¾èµ–æ˜¯å¦æ»¡è¶³
                        dependencies = task.get("dependencies", [])
                        unmet_deps = self._check_unmet_dependencies(dependencies)
                        
                        if unmet_deps:
                            result = f"é”™è¯¯: ä»»åŠ¡ {task_id} çš„ä¾èµ–æœªæ»¡è¶³\næœªå®Œæˆçš„ä¾èµ–: {', '.join(unmet_deps)}\nè¯·å…ˆå®Œæˆä¾èµ–ä»»åŠ¡ã€‚"
                        else:
                            # åˆ†é…ä»»åŠ¡ç»™ Worker æ‰§è¡Œ
                            result = await self._assign_task_to_worker(task, instructions)
                
                elif name == "assign_tasks_parallel":
                    # å¹¶è¡Œåˆ†é…å¤šä¸ªä»»åŠ¡ï¼ˆå¸¦æ™ºèƒ½è°ƒåº¦ï¼‰
                    task_ids = args.get("task_ids", [])
                    max_concurrent = args.get("max_concurrent", 3)
                    
                    if not task_ids:
                        result = "é”™è¯¯: æœªæä¾›ä»»åŠ¡IDåˆ—è¡¨"
                    else:
                        result = await self._assign_tasks_parallel_smart(task_ids, max_concurrent)
                
                elif name == "list_tasks":
                    status_filter = args.get("status", "all")
                    tasks = self.task_manager.get_all_tasks()
                    
                    if status_filter != "all":
                        tasks = [t for t in tasks if t.get("status") == status_filter]
                    
                    if not tasks:
                        result = f"æ²¡æœ‰{status_filter if status_filter != 'all' else ''}ä»»åŠ¡"
                    else:
                        lines = [f"ä»»åŠ¡åˆ—è¡¨ ({len(tasks)}ä¸ª):\n"]
                        for t in tasks:
                            status_icon = {"pending": "â—‹", "in_progress": "â—", "completed": "â—", "failed": "âœ—"}.get(t.get("status"), "â—‹")
                            deps = t.get("dependencies", [])
                            deps_str = f" [ä¾èµ–: {', '.join(deps)}]" if deps else ""
                            files = t.get("files_to_modify", [])
                            files_str = f" [æ–‡ä»¶: {len(files)}ä¸ª]" if files else ""
                            lines.append(f"  {status_icon} {t['id']}: {t['title']} [{t.get('status', 'unknown')}]{deps_str}{files_str}")
                        result = "\n".join(lines)
                
                elif name == "get_task_result":
                    task_id = args.get("task_id")
                    task = self.task_manager.get_task(task_id)
                    if not task:
                        result = f"é”™è¯¯: æœªæ‰¾åˆ°ä»»åŠ¡ {task_id}"
                    else:
                        result = f"ä»»åŠ¡: {task['title']}\nçŠ¶æ€: {task.get('status')}\n"
                        if task.get("result_summary"):
                            result += f"ç»“æœ: {task['result_summary']}\n"
                        if task.get("error_log"):
                            result += f"é”™è¯¯: {task['error_log']}\n"
                
                # ===== æ’ä»¶ç®¡ç†å·¥å…· =====
                elif name == "search_plugin":
                    results = PluginManager.search(args.get("query", ""))
                    result = self._format_search_results(results)
                elif name == "install_plugin":
                    success = await PluginManager.install(args.get("name", ""))
                    if success:
                        await self.mcp_manager.initialize()
                        tools = await self.mcp_manager.get_tools()
                        tools.extend(self._get_evolution_tools())
                    result = "å®‰è£…æˆåŠŸ" if success else "å®‰è£…å¤±è´¥"
                elif name == "analyze_gap":
                    result = "åˆ†æå®Œæˆ"
                
                # ===== MCP å·¥å…· =====
                elif "__" in name:
                    result = await self.mcp_manager.call(name, args)
                else:
                    result = f"æœªçŸ¥å·¥å…·: {name}"
                
                # æ·»åŠ å·¥å…·ç»“æœ
                self.messages.append({
                    "role": "tool",
                    "tool_call_id": tc["id"],
                    "name": name,
                    "content": result
                })
            
            # ç»§ç»­å¯¹è¯
            print(f"{UI.CYAN}[ç»§ç»­]{UI.END} ", end="", flush=True)
            response, tool_calls = await self.model.call_with_messages(self.messages, tools, stream=True)
            
            if response:
                self.messages.append({"role": "assistant", "content": response})
    
    def _get_evolution_tools(self) -> List[Dict]:
        """è·å–è¿›åŒ–å·¥å…·å®šä¹‰"""
        return [
            # ===== ä»»åŠ¡ç®¡ç†å·¥å…·ï¼ˆLeader ä¸“ç”¨ï¼‰=====
            {
                "type": "function",
                "function": {
                    "name": "create_task",
                    "description": "åˆ›å»ºä¸€ä¸ªæ–°ä»»åŠ¡ã€‚Leader å¿…é¡»å…ˆç”¨æ­¤å·¥å…·åˆ›å»ºä»»åŠ¡ï¼Œå†åˆ†é…ç»™ Workerã€‚æ”¯æŒè®¾ç½®ä»»åŠ¡ä¾èµ–ï¼Œåªæœ‰ä¾èµ–ä»»åŠ¡å®Œæˆåæ‰ä¼šæ‰§è¡Œå½“å‰ä»»åŠ¡ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "title": {"type": "string", "description": "ä»»åŠ¡æ ‡é¢˜ï¼ˆç®€æ´ï¼‰"},
                            "description": {"type": "string", "description": "ä»»åŠ¡è¯¦ç»†æè¿°"},
                            "type": {"type": "string", "enum": ["code", "doc", "config", "test", "review", "refactor", "fix"], "description": "ä»»åŠ¡ç±»å‹"},
                            "priority": {"type": "integer", "minimum": 1, "maximum": 5, "description": "ä¼˜å…ˆçº§ï¼ˆ1æœ€é«˜ï¼Œ5æœ€ä½ï¼‰"},
                            "dependencies": {"type": "array", "items": {"type": "string"}, "description": "ä¾èµ–çš„ä»»åŠ¡IDåˆ—è¡¨ï¼Œè¿™äº›ä»»åŠ¡å¿…é¡»å®Œæˆåå½“å‰ä»»åŠ¡æ‰èƒ½æ‰§è¡Œ"},
                            "files_to_modify": {"type": "array", "items": {"type": "string"}, "description": "éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆç”¨äºæ£€æµ‹å¹¶å‘å†²çªï¼‰"},
                            "acceptance_criteria": {"type": "array", "items": {"type": "string"}, "description": "éªŒæ”¶æ ‡å‡†"}
                        },
                        "required": ["title", "description"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "assign_task",
                    "description": "å°†ä»»åŠ¡åˆ†é…ç»™ Worker AI æ‰§è¡Œã€‚Leader å¿…é¡»åœ¨åˆ›å»ºä»»åŠ¡åè°ƒç”¨æ­¤å·¥å…·ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "task_id": {"type": "string", "description": "è¦åˆ†é…çš„ä»»åŠ¡ID"},
                            "instructions": {"type": "string", "description": "ç»™ Worker çš„é¢å¤–æ‰§è¡ŒæŒ‡ä»¤"}
                        },
                        "required": ["task_id"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "assign_tasks_parallel",
                    "description": "å¹¶è¡Œåˆ†é…å¤šä¸ªç‹¬ç«‹ä»»åŠ¡ç»™ Worker AI æ‰§è¡Œã€‚ç”¨äºæ— ä¾èµ–å…³ç³»çš„ä»»åŠ¡å¹¶å‘æ‰§è¡Œã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "task_ids": {"type": "array", "items": {"type": "string"}, "description": "è¦å¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡IDåˆ—è¡¨"},
                            "max_concurrent": {"type": "integer", "minimum": 1, "maximum": 5, "description": "æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤3ï¼‰"}
                        },
                        "required": ["task_ids"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "list_tasks",
                    "description": "åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡åŠå…¶çŠ¶æ€",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "status": {"type": "string", "enum": ["all", "pending", "in_progress", "completed", "failed"], "description": "ç­›é€‰çŠ¶æ€"}
                        }
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_task_result",
                    "description": "è·å–å·²å®Œæˆä»»åŠ¡çš„è¯¦ç»†ç»“æœ",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "task_id": {"type": "string", "description": "ä»»åŠ¡ID"}
                        },
                        "required": ["task_id"]
                    }
                }
            },
            # ===== æ’ä»¶ç®¡ç†å·¥å…· =====
            {
                "type": "function",
                "function": {
                    "name": "search_plugin",
                    "description": "æœç´¢MCPæ’ä»¶",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {"type": "string", "description": "æœç´¢å…³é”®è¯"}
                        }
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "install_plugin",
                    "description": "å®‰è£…MCPæ’ä»¶",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "name": {"type": "string", "description": "æ’ä»¶åç§°"}
                        },
                        "required": ["name"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "analyze_gap",
                    "description": "åˆ†æèƒ½åŠ›å·®è·",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "task": {"type": "string", "description": "ä»»åŠ¡æè¿°"}
                        }
                    }
                }
            }
        ]
    
    def _check_unmet_dependencies(self, dependencies: List[str]) -> List[str]:
        """
        æ£€æŸ¥æœªæ»¡è¶³çš„ä¾èµ–
        
        Args:
            dependencies: ä¾èµ–ä»»åŠ¡IDåˆ—è¡¨
            
        Returns:
            æœªå®Œæˆçš„ä¾èµ–ä»»åŠ¡IDåˆ—è¡¨
        """
        unmet = []
        for dep_id in dependencies:
            dep_task = self.task_manager.get_task(dep_id)
            if not dep_task or dep_task.get("status") != "completed":
                unmet.append(dep_id)
        return unmet
    
    def _detect_file_conflicts(self, tasks: List[Dict]) -> Dict[str, List[str]]:
        """
        æ£€æµ‹ä»»åŠ¡é—´çš„æ–‡ä»¶å†²çª
        
        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨
            
        Returns:
            å†²çªæ˜ å°„: {æ–‡ä»¶è·¯å¾„: [å†²çªçš„ä»»åŠ¡IDåˆ—è¡¨]}
        """
        file_to_tasks = {}
        
        for task in tasks:
            files = task.get("files_to_modify", [])
            for f in files:
                if f not in file_to_tasks:
                    file_to_tasks[f] = []
                file_to_tasks[f].append(task["id"])
        
        # åªä¿ç•™æœ‰å†²çªçš„æ–‡ä»¶
        conflicts = {f: task_ids for f, task_ids in file_to_tasks.items() if len(task_ids) > 1}
        return conflicts
    
    def _get_execution_groups(self, tasks: List[Dict]) -> List[List[Dict]]:
        """
        æ ¹æ®ä¾èµ–å…³ç³»å°†ä»»åŠ¡åˆ†ç»„ï¼Œæ¯ç»„å†…çš„ä»»åŠ¡å¯ä»¥å¹¶è¡Œæ‰§è¡Œ
        
        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨
            
        Returns:
            æ‰§è¡Œåˆ†ç»„åˆ—è¡¨ï¼Œæ¯ç»„å†…çš„ä»»åŠ¡äº’ä¸ä¾èµ–
        """
        if not tasks:
            return []
        
        # æ„å»ºä»»åŠ¡IDåˆ°ä»»åŠ¡çš„æ˜ å°„
        task_map = {t["id"]: t for t in tasks}
        task_ids = set(task_map.keys())
        
        # æ„å»ºä¾èµ–å›¾
        dependencies = {}
        for t in tasks:
            deps = set(t.get("dependencies", []))
            # åªè€ƒè™‘åˆ—è¡¨å†…çš„ä¾èµ–
            dependencies[t["id"]] = deps & task_ids
        
        # æ£€æµ‹æ–‡ä»¶å†²çªï¼Œå°†å†²çªçš„ä»»åŠ¡è§†ä¸ºäº’ç›¸ä¾èµ–
        conflicts = self._detect_file_conflicts(tasks)
        for file_path, conflicting_ids in conflicts.items():
            for i, tid1 in enumerate(conflicting_ids):
                for tid2 in conflicting_ids[i+1:]:
                    # æ·»åŠ åŒå‘ä¾èµ–ï¼ˆè§†ä¸ºå†²çªï¼‰
                    dependencies[tid1].add(tid2)
                    dependencies[tid2].add(tid1)
        
        # æ‹“æ‰‘æ’åºåˆ†ç»„
        groups = []
        remaining = set(task_ids)
        completed = set()
        
        while remaining:
            # æ‰¾å‡ºæ‰€æœ‰ä¾èµ–å·²æ»¡è¶³çš„ä»»åŠ¡
            ready = []
            for tid in remaining:
                if dependencies[tid] <= completed:
                    ready.append(task_map[tid])
            
            if not ready:
                # å­˜åœ¨å¾ªç¯ä¾èµ–ï¼Œå¼ºåˆ¶é€‰ä¸€ä¸ªï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼Œä½†ä½œä¸ºä¿é™©ï¼‰
                warn(f"æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–ï¼Œå¼ºåˆ¶é€‰æ‹©ä»»åŠ¡: {remaining}")
                ready = [task_map[next(iter(remaining))]]
            
            groups.append(ready)
            for t in ready:
                completed.add(t["id"])
                remaining.discard(t["id"])
        
        return groups
    
    def _format_search_results(self, results: list) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
        if not results:
            return "æœªæ‰¾åˆ°åŒ¹é…æ’ä»¶"
        
        lines = ["æ‰¾åˆ°ä»¥ä¸‹æ’ä»¶ï¼š\n"]
        for p in results[:10]:
            lines.append(f"- {p.name}: {p.description}")
            if hasattr(p, 'required_env') and p.required_env:
                lines.append(f"  éœ€è¦ç¯å¢ƒå˜é‡: {', '.join(p.required_env)}")
        
        return "\n".join(lines)
    
    async def plan_tasks(self, user_request: str) -> bool:
        """è§„åˆ’ä»»åŠ¡"""
        if not self.model:
            UI.error("æ¨¡å‹æœªåˆå§‹åŒ–")
            return False
        
        UI.info("æ­£åœ¨åˆ†æéœ€æ±‚å¹¶è§„åˆ’ä»»åŠ¡...")
        
        system_prompt = f"""ä½ æ˜¯ä»»åŠ¡è§„åˆ’ä¸“å®¶ã€‚

{self.leader_guide}

è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œåˆ›å»ºè¯¦ç»†çš„ä»»åŠ¡åˆ—è¡¨ã€‚
"""
        
        response, _ = self.model.call(user_request, system_prompt)
        tasks = self._parse_tasks_from_response(response)
        
        for task_data in tasks:
            self.task_manager.create_task(**task_data)
        
        UI.success(f"å·²åˆ›å»º {len(tasks)} ä¸ªä»»åŠ¡")
        self.task_manager.show_progress()
        
        return True
    
    def _parse_tasks_from_response(self, response: str) -> List[Dict]:
        """ä»æ¨¡å‹å“åº”ä¸­è§£æä»»åŠ¡"""
        tasks = []
        
        try:
            json_blocks = re.findall(r'```json\s*(.*?)\s*```', response, re.DOTALL)
            
            for block in json_blocks:
                try:
                    data = json.loads(block)
                    if isinstance(data, list):
                        tasks.extend(data)
                    elif isinstance(data, dict) and "tasks" in data:
                        tasks.extend(data["tasks"])
                except:
                    continue
            
            if not tasks:
                data = json.loads(response)
                if isinstance(data, list):
                    tasks = data
                elif isinstance(data, dict) and "tasks" in data:
                    tasks = data["tasks"]
                    
        except json.JSONDecodeError:
            tasks = [{
                "title": "æ‰§è¡Œç”¨æˆ·éœ€æ±‚",
                "description": response,
                "type": "code",
                "priority": 3,
                "dependencies": [],
            }]
        
        return tasks
    
    async def _assign_task_to_worker(self, task: Dict, instructions: str = "") -> str:
        """
        åˆ†é…ä»»åŠ¡ç»™ Workerï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œè¿”å›å­—ç¬¦ä¸²ç»“æœï¼‰
        
        Args:
            task: ä»»åŠ¡å­—å…¸
            instructions: é¢å¤–æŒ‡ä»¤
            
        Returns:
            æ‰§è¡Œç»“æœå­—ç¬¦ä¸²
        """
        if not self.worker_model:
            return "é”™è¯¯: Worker æ¨¡å‹æœªé…ç½®"
        
        # è®¾ç½®ä»»åŠ¡çŠ¶æ€ä¸ºè¿›è¡Œä¸­
        self.task_manager.set_task_status(task["id"], "in_progress")
        
        # å¦‚æœæœ‰é¢å¤–æŒ‡ä»¤ï¼Œæ·»åŠ åˆ°ä»»åŠ¡æè¿°ä¸­
        if instructions:
            task = task.copy()
            task["description"] = f"{task.get('description', '')}\n\né¢å¤–æŒ‡ä»¤: {instructions}"
        
        # åˆ›å»º Worker å®ä¾‹å¹¶æ‰§è¡Œ
        worker = WorkerAI(
            ai_dir=self.ai_dir,
            task=task,
            model_interface=self.worker_model,
            mcp_manager=self.mcp_manager,
            leader=self
        )
        
        UI.section(f"Worker æ‰§è¡Œä»»åŠ¡: {task['title']}")
        success, result = await worker.execute()
        
        if success:
            self.task_manager.set_task_status(task["id"], "completed", result=result)
            return f"âœ… ä»»åŠ¡ {task['id']} å®Œæˆ\nç»“æœ: {result[:500]}..." if len(result) > 500 else f"âœ… ä»»åŠ¡ {task['id']} å®Œæˆ\nç»“æœ: {result}"
        else:
            self.task_manager.set_task_status(task["id"], "failed", error=result)
            return f"âŒ ä»»åŠ¡ {task['id']} å¤±è´¥\né”™è¯¯: {result[:500]}..." if len(result) > 500 else f"âŒ ä»»åŠ¡ {task['id']} å¤±è´¥\né”™è¯¯: {result}"
    
    async def _assign_tasks_parallel(self, task_ids: List[str], max_concurrent: int = 3) -> str:
        """
        å¹¶è¡Œåˆ†é…å¤šä¸ªä»»åŠ¡ç»™ Worker æ‰§è¡Œï¼ˆå·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ _assign_tasks_parallel_smartï¼‰
        """
        return await self._assign_tasks_parallel_smart(task_ids, max_concurrent)
    
    async def _assign_tasks_parallel_smart(self, task_ids: List[str], max_concurrent: int = 3) -> str:
        """
        æ™ºèƒ½å¹¶è¡Œåˆ†é…å¤šä¸ªä»»åŠ¡ç»™ Worker æ‰§è¡Œ
        
        ç‰¹æ€§ï¼š
        1. è‡ªåŠ¨æ£€æµ‹ä»»åŠ¡ä¾èµ–ï¼ŒæŒ‰ä¾èµ–é¡ºåºæ‰§è¡Œ
        2. æ£€æµ‹æ–‡ä»¶å†²çªï¼Œé¿å…å¤šä¸ª Worker åŒæ—¶ä¿®æ”¹åŒä¸€æ–‡ä»¶
        3. è‡ªåŠ¨åˆ†ç»„å¹¶è¡Œæ‰§è¡Œæ— å†²çªçš„ä»»åŠ¡
        
        Args:
            task_ids: ä»»åŠ¡IDåˆ—è¡¨
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
            
        Returns:
            æ‰§è¡Œç»“æœæ±‡æ€»
        """
        if not self.worker_model:
            return "é”™è¯¯: Worker æ¨¡å‹æœªé…ç½®"
        
        # è·å–æ‰€æœ‰å¾…å¤„ç†ä»»åŠ¡
        tasks = []
        invalid_ids = []
        dependency_blocked = []
        
        all_tasks = self.task_manager.get_all_tasks()
        task_status = {t["id"]: t.get("status") for t in all_tasks}
        
        for task_id in task_ids:
            task = self.task_manager.get_task(task_id)
            if not task:
                invalid_ids.append(task_id)
            elif task.get("status") != "pending":
                invalid_ids.append(f"{task_id}(çŠ¶æ€:{task.get('status')})")
            else:
                # æ£€æŸ¥ä¾èµ–æ˜¯å¦æ»¡è¶³ï¼ˆæ£€æŸ¥æ‰€æœ‰ä¾èµ–ï¼Œä¸åªæ˜¯åˆ—è¡¨å†…çš„ï¼‰
                dependencies = task.get("dependencies", [])
                unmet_deps = [d for d in dependencies if task_status.get(d) != "completed"]
                
                if unmet_deps:
                    dependency_blocked.append(f"{task_id}(ä¾èµ–:{','.join(unmet_deps)})")
                else:
                    tasks.append(task)
        
        # æ„å»ºç»“æœæ¶ˆæ¯
        messages = []
        if invalid_ids:
            messages.append(f"æ— æ•ˆä»»åŠ¡: {', '.join(invalid_ids)}")
        if dependency_blocked:
            messages.append(f"ä¾èµ–æœªæ»¡è¶³: {', '.join(dependency_blocked)}")
        
        if not tasks:
            return "é”™è¯¯: æ²¡æœ‰å¯æ‰§è¡Œçš„ä»»åŠ¡\n" + "\n".join(messages)
        
        if messages:
            info("\n".join(messages))
        
        # æ£€æµ‹æ–‡ä»¶å†²çª
        conflicts = self._detect_file_conflicts(tasks)
        if conflicts:
            conflict_info = []
            for f, task_ids in conflicts.items():
                conflict_info.append(f"  {f}: {', '.join(task_ids)}")
            info(f"æ£€æµ‹åˆ°æ–‡ä»¶å†²çª:\n" + "\n".join(conflict_info))
        
        # æŒ‰ä¾èµ–å’Œå†²çªåˆ†ç»„
        execution_groups = self._get_execution_groups(tasks)
        
        info(f"å¼€å§‹æ‰§è¡Œ {len(tasks)} ä¸ªä»»åŠ¡ï¼Œåˆ†ä¸º {len(execution_groups)} æ‰¹ï¼ˆæœ€å¤§å¹¶å‘: {max_concurrent}ï¼‰")
        
        # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘
        semaphore = asyncio.Semaphore(max_concurrent)
        results = {}
        
        async def execute_with_semaphore(task: Dict):
            async with semaphore:
                task_log(f"Worker å¼€å§‹: {task['title']}")
                self.task_manager.set_task_status(task["id"], "in_progress")
                
                worker = WorkerAI(
                    ai_dir=self.ai_dir,
                    task=task,
                    model_interface=self.worker_model,
                    mcp_manager=self.mcp_manager,
                    leader=self
                )
                
                success, result = await worker.execute()
                
                if success:
                    self.task_manager.set_task_status(task["id"], "completed", result=result)
                    results[task["id"]] = f"âœ… å®Œæˆ"
                else:
                    self.task_manager.set_task_status(task["id"], "failed", error=result)
                    results[task["id"]] = f"âŒ å¤±è´¥: {result[:100]}"
        
        # åˆ†æ‰¹æ‰§è¡Œ
        start_time = time.time()
        
        for group_idx, group in enumerate(execution_groups):
            if len(execution_groups) > 1:
                info(f"æ‰§è¡Œç¬¬ {group_idx + 1}/{len(execution_groups)} æ‰¹ä»»åŠ¡ ({len(group)} ä¸ª)")
            
            # æ£€æŸ¥è¿™æ‰¹ä»»åŠ¡æ˜¯å¦æœ‰å‰ç½®å¤±è´¥å¯¼è‡´ä¾èµ–ä¸æ»¡è¶³
            ready_tasks = []
            for t in group:
                deps = t.get("dependencies", [])
                failed_deps = [d for d in deps if results.get(d, "").startswith("âŒ")]
                if failed_deps:
                    results[t["id"]] = f"â­ï¸ è·³è¿‡: ä¾èµ–ä»»åŠ¡å¤±è´¥ ({', '.join(failed_deps)})"
                else:
                    ready_tasks.append(t)
            
            if ready_tasks:
                await asyncio.gather(*[execute_with_semaphore(t) for t in ready_tasks])
        
        elapsed = time.time() - start_time
        
        # æ˜¾ç¤ºè¿›åº¦
        self._show_progress_bar(len(tasks), elapsed)
        
        # æ±‡æ€»ç»“æœ
        completed = sum(1 for r in results.values() if "âœ…" in r)
        failed = sum(1 for r in results.values() if "âŒ" in r)
        skipped = sum(1 for r in results.values() if "â­ï¸" in r)
        
        summary = f"\næ‰§è¡Œå®Œæˆ (è€—æ—¶: {elapsed:.1f}ç§’)\n"
        summary += f"  æˆåŠŸ: {completed}/{len(tasks)}\n"
        summary += f"  å¤±è´¥: {failed}/{len(tasks)}\n"
        if skipped > 0:
            summary += f"  è·³è¿‡: {skipped}/{len(tasks)}\n"
        if dependency_blocked:
            summary += f"  ä¾èµ–é˜»å¡: {len(dependency_blocked)}\n"
        
        summary += "\nä»»åŠ¡ç»“æœ:\n"
        for task_id in task_ids:
            if task_id in results:
                summary += f"  - {task_id}: {results[task_id]}\n"
        
        return summary
    
    def _show_progress_bar(self, total: int, elapsed: float):
        """æ˜¾ç¤ºè¿›åº¦æ¡"""
        stats = self.task_manager.get_statistics()
        completed = stats.get("completed", 0)
        failed = stats.get("failed", 0)
        total_tasks = stats.get("total", 1)
        
        progress = completed / total_tasks if total_tasks > 0 else 0
        bar_length = 30
        filled = int(bar_length * progress)
        
        bar = f"{'â–ˆ' * filled}{'â–‘' * (bar_length - filled)}"
        
        print(f"\n{UI.CYAN}[è¿›åº¦]{UI.END} [{UI.GREEN}{bar}{UI.END}] {progress*100:.0f}% | "
              f"å®Œæˆ: {completed} | å¤±è´¥: {failed} | è€—æ—¶: {elapsed:.1f}s")
    
    async def assign_task_to_worker(self, task: Dict) -> Tuple[bool, str]:
        """åˆ†é…ä»»åŠ¡ç»™ Worker"""
        if not self.worker_model:
            return False, "Worker æ¨¡å‹æœªé…ç½®"
        
        self.task_manager.set_task_status(task["id"], "in_progress")
        
        worker = WorkerAI(
            ai_dir=self.ai_dir,
            task=task,
            model_interface=self.worker_model,
            mcp_manager=self.mcp_manager,
            leader=self
        )
        
        success, result = await worker.execute()
        
        if success:
            self.task_manager.set_task_status(task["id"], "completed", result=result)
        else:
            self.task_manager.set_task_status(task["id"], "failed", error=result)
        
        return success, result
    
    def request_user_help(self, message: str) -> str:
        """å‘ç”¨æˆ·è¯·æ±‚å¸®åŠ©"""
        UI.section("éœ€è¦æ‚¨çš„å¸®åŠ©")
        print(f"\n  {message}\n")
        
        response = UI.input("è¯·æä¾›æŒ‡å¯¼æˆ–å¸®åŠ©")
        return response


class WorkerAI:
    """Worker AI - ä»»åŠ¡æ‰§è¡Œ"""
    
    def __init__(
        self,
        ai_dir: str,
        task: Dict,
        model_interface: ModelInterface,
        mcp_manager: MCPToolManager,
        leader: LeaderAI
    ):
        self.ai_dir = ai_dir
        self.root_dir = os.path.dirname(ai_dir)
        self.task = task
        self.model = model_interface
        self.mcp_manager = mcp_manager
        self.leader = leader
        self.worker_guide = self._load_guide()
        self.tools = None
    
    def _load_guide(self) -> str:
        """åŠ è½½ Worker æŒ‡å—"""
        template_path = os.path.join(
            os.path.dirname(os.path.dirname(__file__)),
            "templates",
            "README_for_worker.md"
        )
        if os.path.exists(template_path):
            try:
                with open(template_path, 'r', encoding='utf-8') as f:
                    return f.read()
            except:
                pass
        return ""
    
    async def execute(self) -> Tuple[bool, str]:
        """æ‰§è¡Œä»»åŠ¡"""
        try:
            # ç¡®ä¿ MCP ç®¡ç†å™¨å·²åˆå§‹åŒ–
            if not self.mcp_manager:
                return False, "MCP ç®¡ç†å™¨æœªåˆå§‹åŒ–"
            
            # é‡æ–°åˆå§‹åŒ–ä»¥ç¡®ä¿å·¥å…·å¯ç”¨
            await self.mcp_manager.initialize()
            
            # è·å– MCP å·¥å…·
            self.tools = await self.mcp_manager.get_tools()
            
            if not self.tools:
                UI.warn("æœªæ‰¾åˆ°å¯ç”¨çš„ MCP å·¥å…·ï¼Œè¯·å…ˆå®‰è£…æ’ä»¶: ai install <plugin-name>")
            
            # æ„å»ºä»»åŠ¡æç¤º
            system_prompt = f"""ä½ æ˜¯ Worker AIï¼Œè´Ÿè´£æ‰§è¡Œå…·ä½“ä»»åŠ¡ã€‚

{self.worker_guide}

å½“å‰ä»»åŠ¡:
- ID: {self.task.get('id')}
- æ ‡é¢˜: {self.task.get('title')}
- æè¿°: {self.task.get('description')}
- ç±»å‹: {self.task.get('type')}
- éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶: {self.task.get('files_to_modify', [])}
- éªŒæ”¶æ ‡å‡†: {self.task.get('acceptance_criteria', [])}

å·¥ä½œç›®å½•: {self.root_dir}

è§„åˆ™ï¼š
1. ä¸è¦å‘ç”¨æˆ·è¯·æ±‚äº¤äº’æˆ–å¸®åŠ©
2. ä½¿ç”¨å¯ç”¨çš„ MCP å·¥å…·å®Œæˆä»»åŠ¡
3. å¦‚æœé‡åˆ°æ— æ³•è§£å†³çš„é—®é¢˜ï¼Œè¯´æ˜å…·ä½“é”™è¯¯
4. å®Œæˆåæä¾›ç®€è¦ç»“æœæ‘˜è¦

å¯ç”¨å·¥å…·æ•°é‡: {len(self.tools)}
"""
            
            user_prompt = f"è¯·æ‰§è¡Œä»»åŠ¡: {self.task.get('title')}\n\n{self.task.get('description')}"
            
            # åˆå§‹åŒ–æ¶ˆæ¯
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            return await self._execution_loop(messages)
            
        except Exception as e:
            import traceback
            return False, f"æ‰§è¡Œå¼‚å¸¸: {e}\n{traceback.format_exc()}"
    
    async def _execution_loop(self, messages: List[Dict]) -> Tuple[bool, str]:
        """æ‰§è¡Œå¾ªç¯ï¼ˆä¿®å¤P1ï¼šæ·»åŠ ä¸Šä¸‹æ–‡çª—å£ç®¡ç†ï¼‰"""
        max_iterations = 20
        iteration = 0
        max_message_count = 50  # æœ€å¤§æ¶ˆæ¯æ•°ï¼ˆä¿®å¤P1ï¼šé˜²æ­¢ä¸Šä¸‹æ–‡æº¢å‡ºï¼‰
        
        while iteration < max_iterations:
            iteration += 1
            
            # ä¿®å¤P1ï¼šè£å‰ªæ¶ˆæ¯å†å²ï¼ˆä¿ç•™ç³»ç»Ÿæç¤º + æœ€è¿‘çš„æ¶ˆæ¯ï¼‰
            if len(messages) > max_message_count:
                # ä¿ç•™systemæ¶ˆæ¯ï¼ˆç¬¬ä¸€æ¡ï¼‰+ æœ€è¿‘çš„æ¶ˆæ¯
                system_msg = messages[0] if messages[0]["role"] == "system" else None
                recent_messages = messages[-(max_message_count-1):]
                messages = ([system_msg] if system_msg else []) + recent_messages
                UI.warn(f"æ¶ˆæ¯å†å²å·²è£å‰ªè‡³ {len(messages)} æ¡ä»¥é˜²æ­¢æº¢å‡º")
            
            # ä½¿ç”¨å®Œæ•´çš„æ¶ˆæ¯å†å²è°ƒç”¨æ¨¡å‹
            response, tool_calls = await self.model.call_with_messages(messages, self.tools, stream=True)
            
            # æ·»åŠ åŠ©æ‰‹å“åº”
            if response or tool_calls:
                messages.append({
                    "role": "assistant",
                    "content": response if response else None,
                    "tool_calls": tool_calls if tool_calls else None
                })
            
            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä»»åŠ¡å®Œæˆ
            if not tool_calls:
                return True, response or "ä»»åŠ¡å®Œæˆ"
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            for tc in tool_calls:
                result = await self._handle_tool_call(tc)
                
                messages.append({
                    "role": "tool",
                    "tool_call_id": tc["id"],
                    "name": tc["function"]["name"],
                    "content": result
                })
        
        return False, "è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°"
    
    async def _handle_tool_call(self, tc: Dict) -> str:
        """å¤„ç†å·¥å…·è°ƒç”¨"""
        name = tc["function"]["name"]
        
        try:
            args = json.loads(tc["function"]["arguments"])
        except:
            args = {}
        
        UI.info(f"æ‰§è¡Œ: {name}")
        
        # MCP å·¥å…·è°ƒç”¨
        if "__" in name:
            result = await self.mcp_manager.call(name, args)
            return result
        
        # å†…ç½®å·¥å…·
        if name == "report_error_to_leader":
            return self._report_to_leader(args.get("error", ""))
        
        return f"æœªçŸ¥å·¥å…·: {name}"
    
    def _report_to_leader(self, error: str) -> str:
        """å‘ Leader æŠ¥å‘Šé”™è¯¯"""
        self.leader.task_manager.add_note(
            self.task["id"],
            f"Worker æŠ¥å‘Šé”™è¯¯: {error}",
            "worker"
        )
        return f"å·²å°†é”™è¯¯æŠ¥å‘Šç»™ Leader: {error}"


async def run_leader_worker_session(ai_dir: str):
    """å¯åŠ¨ Leader-Worker ä¼šè¯"""
    leader = LeaderAI(ai_dir)
    await leader.start_session()
